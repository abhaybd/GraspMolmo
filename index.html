<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GraspMolmo is a generalizable open-vocabulary task-oriented grasping model that predicts semantically appropriate grasps given a natural language instruction.">
  <meta name="keywords" content="GraspMolmo, Grasping, Task-Oriented Grasping, Molmo, Synthetic Data, VLM, Robotics, Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GraspMolmo</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/sync_vids.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://abhaybd.github.io/">Abhay Deshpande</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/yuquand/">Yuquan Deng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://arijitray1993.github.io/">Arijit Ray</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jordisalvador-image.blogspot.com/">Jordi Salvador</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.semanticscholar.org/author/Winson-Han/1443358534">Winson Han</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://duanjiafei.com/">Jiafei Duan</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://kuohaozeng.github.io/">Kuo-Hao Zeng</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.utexas.edu/~yukez/">Yuke Zhu</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://ranjaykrishna.com/">Ranjay Krishna</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://rosehendrix.com/">Rose Hendrix</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>PRIOR @ Allen Institute for AI,</span>
            <span class="author-block"><sup>2</sup>Boston University,</span>
            <span class="author-block"><sup>3</sup>University of Washington,</span>
            <span class="author-block"><sup>4</sup>Vercept,</span>
            <span class="author-block"><sup>5</sup>UT Austin</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/abhaybd/GraspMolmo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="teaser-video-container">
        <div class="teaser-video-row">
          <video muted class="synced synced-teaser">
            <source src="./static/videos/robot/bottle_lid.mp4" type="video/mp4">
          </video>
          <video muted class="synced synced-teaser">
            <source src="./static/videos/robot/frenchpress_pour.mp4" type="video/mp4">
          </video>
        </div>
        <div class="teaser-video-row">
          <video muted class="synced synced-teaser">
            <source src="./static/videos/robot/flowers.mp4" type="video/mp4">
          </video>
          <video muted class="synced synced-teaser">
            <source src="./static/videos/robot/phone_answer.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present GraspMolmo, a generalizable open-vocabulary task-oriented grasping (TOG) model. GraspMolmo predicts
            semantically appropriate, stable grasps conditioned on a natural language instruction and a single RGB-D frame.
            For instance, given "pour me some tea," GraspMolmo selects a grasp on a teapot handle rather than its body.
          </p>
          <p>
            Unlike prior TOG methods, which are limited by small datasets, simplistic language, and uncluttered scenes,
            GraspMolmo learns from a large-scale synthetic dataset of 379k samples featuring cluttered environments and
            diverse, realistic task descriptions. We fine-tune the Molmo visual-language model on this data, enabling
            GraspMolmo to generalize to novel open-vocabulary instructions and objects.
          </p>
          <p>
            In challenging real-world evaluations, GraspMolmo achieves state-of-the-art results, with a 70% prediction
            success on complex tasks, compared to the 35% achieved by the next best alternative. GraspMolmo also
            successfully demonstrates the ability to predict semantically correct bimanual grasps zero-shot.
          </p>
          <p>
            We release our synthetic dataset, code, model, and benchmarks to accelerate research in task-semantic robotic
            manipulation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <img src="./static/images/teaser_transparent.png" alt="Overview of the PRISM dataset and GraspMolmo model">
    <h2 class="subtitle has-text-centered">
      GraspMolmo is a generalizable open-vocabulary task-oriented grasping model that predicts semantically appropriate grasps given a natural language instruction.
    </h2>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Data Generation</h2>

    <!-- Data Generation -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h3 class="title is-3">PRISM Dataset</h3>
          <p>
            Lorem ipsum dolor sit amet consectetur adipisicing elit. Minus assumenda repudiandae repellat eveniet modi consequatur quisquam laudantium, enim, blanditiis odio quam officia? Dolor, mollitia nesciunt reprehenderit repudiandae laboriosam nobis iste.
          </p>
          <img src="./static/images/datagen_overview.png" alt="Overview of the PRISM data generation pipeline">
        </div>
      </div>
    </div>
    <!--/ Data Generation -->

    <!-- TaskGrasp-Image -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h3 class="title is-3">TaskGrasp-Image</h2>
          <p>
            Lorem ipsum dolor sit amet consectetur adipisicing elit. Minus assumenda repudiandae repellat eveniet modi consequatur quisquam laudantium, enim, blanditiis odio quam officia? Dolor, mollitia nesciunt reprehenderit repudiandae laboriosam nobis iste.
          </p>
          <img src="./static/images/datagen_overview.png" alt="Overview of the PRISM data generation pipeline">
        </div>
      </div>
    </div>
    <!--/ TaskGrasp-Image -->
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Evaluation</h2>
    <!-- 
      Experimental Results
      - Table
      - Regression plot
      Real-world
      - Pictures of scenes
      - Full task table
      Bimanual
      - Videos
    -->
    <!-- Experimental Results -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h3 class="title is-3">Experimental Results</h2>
            <div class="columns is-multiline is-centered">
              <div class="column is-full">
                <p>
                  We evaluate GraspMolmo and the most appropriate baseline on three distinct benchmark settings, progressively increasing in complexity and real-world applicability: 
                  a benchmark from literature with simple objects and minimal visual diversity, a synthetic held-out dataset of fully composed scenes with unseen objects, and finally, 
                  real-world transfer scenarios. The performance gap between methods widens notably as we progress from simpler to more complex evaluation scenarios, revealing
                  fundamental differences in approach capabilities that are not apparent in basic benchmarks.
                </p>
                <p>
                  We see that GraspMolmo outperforms all baselines in all evaluations, especially in real-world transfer experiments. This demonstrates its powerful generalization capabilities,
                  and its ability to handle complexity in scene composition, object diversity, and task specification.
                </p>
                <p>
                  We also note that performance on PRISM-Test correlates well with real-world performance, while TaskGrasp-Image does not.
                  This further demonstrates the importance and utility of the PRISM-Test benchmark.
                </p>
              </div>
              <div class="column is-6">
                <img src="static/images/correlations.png" alt="PRISM-Test is a better predictor of real-world performance than TaskGrasp-Image.">
                <p class="has-text-centered">
                  PRISM-Test is a better predictor of real-world performance than TaskGrasp-Image.
                </p>
              </div>
              <div class="column is-full">
                <div class="table-container has-text-centered">
                <table class="results-table">
                  <tr>
                    <th></th>
                    <th>TaskGrasp-Image</th>
                    <th>PRISM-Test</th>
                    <th>PRISM-Real (Prediction)</th>
                    <th>PRISM-Real (Overall)</th>
                  </tr>
                  <tr>
                    <td>Random</td>
                    <td>54.5%</td>
                    <td>29.3%</td>
                    <td>-</td>
                    <td>-</td>
                  </tr>
                  <tr>
                    <td>GraspGPT</td>
                    <td>72.3%</td>
                    <td>40.0%</td>
                    <td>35.1%</td>
                    <td>24.0%</td>
                  </tr>
                  <tr>
                    <td>Molmo</td>
                    <td>75.6%</td>
                    <td>49.8%</td>
                    <td>33.7%</td>
                    <td>31.0%</td>
                  </tr>
                  <tr>
                    <td><b>GraspMolmo</b></td>
                    <td><b>76.7%</b></td>
                    <td><b>62.5%</b></td>
                    <td><b>70.4%</b></td>
                    <td><b>61.1%</b></td>
                  </tr>
                </table>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Experimental Results -->

    <!-- Real-World Evaluation -->
    <h3 class="title is-3">Real-World Evaluation</h3>
    <div class="columns is-centered is-multiline">
      <div class="column is-full">
        <div class="columns is-centered">
          <div class="column is-4">
            <img src="static/images/scenes/scene1.jpg" alt="Scene 1">
            <p class="has-text-centered">Scene 1</p>
          </div>
          <div class="column is-4">
            <img src="static/images/scenes/scene2.jpg" alt="Scene 2">
            <p class="has-text-centered">Scene 2</p>
          </div>
          <div class="column is-4">
            <img src="static/images/scenes/scene3.jpg" alt="Scene 3">
            <p class="has-text-centered">Scene 3</p>
          </div>
        </div>
      </div>
      <div class="column is-9">
        <div class="content">
          <div class="table-container has-text-centered">
            <table class="scenes-table">
              <tr>
                <td rowspan="6">Scene 1</td>
                <td rowspan="2">French Press</td>
                <td>"Pour coffee from the french press"</td>
              </tr>
              <tr>
                <td>"Press down the knob of the plunger of the french press"</td>
              </tr>
              <tr>
                <td rowspan="2">Kitchen Knife</td>
                <td>"Use the knife to cut fruit"</td>
              </tr>
              <tr>
                <td>"Hand me the knife safely"</td>
              </tr>
              <tr>
                <td rowspan="2">Mug</td>
                <td>"Pour the water out of the blue mug"</td>
              </tr>
              <tr>
                <td>"Hang the blue mug onto a hook by the handle"</td>
              </tr>
              <tr>
                <td rowspan="6">Scene 2</td>
                <td rowspan="2">Water Bottle</td>
                <td>"Open the lid of the water bottle"</td>
              </tr>
              <tr>
                <td>"Give me some water"</td>
              </tr>
              <tr>
                <td rowspan="2">Sink</td>
                <td>"Adjust the faucet"</td>
              </tr>
              <tr>
                <td>"Turn on the sink"</td>
              </tr>
              <tr>
                <td rowspan="2">Spray Bottle</td>
                <td>"Spray cleaning solution with the spray bottle"</td>
              </tr>
              <tr>
                <td>"Unscrew the spray bottle"</td>
              </tr>
              <tr>
                <td rowspan="6">Scene 3</td>
                <td rowspan="2">Books</td>
                <td>"Pass the book written by Greg Bear"</td>
              </tr>
              <tr>
                <td>"Pass the book written by Orson Scott Card"</td>
              </tr>
              <tr>
                <td rowspan="2">Telephone</td>
                <td>"Answer the phone"</td>
              </tr>
              <tr>
                <td>"Put the phone back on the hook"</td>
              </tr>
              <tr>
                <td rowspan="2">Flower + Vase</td>
                <td>"Take the flowers out of the vase"</td>
              </tr>
              <tr>
                <td>"Dump the flowers out of the vase"</td>
              </tr>
            </table>            
          </div>
          <p class="has-text-centered">
            A full list of the scenes, objects, and tasks used for real-world evaluation.
          </p>
        </div>
      </div>
    </div>

    <!-- Bimanual -->
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h3 class="title is-3">Extension to Bimanual Grasping</h2>
          <div class="columns is-multiline is-centered">
            <div class="column is-6">
              <video muted class="synced synced-bimanual">
                <source src="./static/videos/robot/bottle.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-6">
              <video muted class="synced synced-bimanual">
                <source src="./static/videos/robot/box.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-8">
              <p class="has-text-centered">
                We also see that GraspMolmo shows impressive capability to predict bimanual grasps, enabling
                complex task-oriented bimanual grasping.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Bimanual -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{deshpande2025graspmolmo,
  author    = {Deshpande, Abhay and Deng, Yuquan and Ray, Arijit and Salvador, Jordi and Han, Winson and Duan, Jiafei and Zeng, Kuo-Hao and Zhu, Yuke and Krishna, Ranjay and Hendrix, Rose},
  title     = {GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation},
  journal   = {arXiv preprint arXiv:XXXXX},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template taken from <a href="https://nerfies.github.io/">NeRFies</a>, by Keunhong Park.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
